#! /usr/bin/env python2.7
# -*- coding: utf-8 -*-

import sys
from tokens import *

tokenizer = LexicalAnalyzer()

data = open(sys.argv[1])
data = data.read()

tokenizer.lexer.input(data)
while True:    
    tok = tokenizer.lexer.token()

    if not tok: break
    if (tok.type != 'SPACE' and tok.type != 'NEWLINE' and tok.type != 'TAB'):

        if len(tok.type) > 9:
            tokenizer.output+="token %s\tvalue (%s) at line %d, column %d\n" %(tok.type,tok.value,tok.lineno,tok.lexpos - tokenizer.beginningOfLine)
        else:
            tokenizer.output+="token %s\t\tvalue (%s) at line %d, column %d\n" %(tok.type,tok.value,tok.lineno,tok.lexpos - tokenizer.beginningOfLine)

if not tokenizer.error:
    print tokenizer.output
else:
    print tokenizer.errorOutput