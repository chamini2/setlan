#!/usr/bin/env python
# -*- coding: utf-8 -*-

############################
#  Proyecto I - CI3725     #
#  Grupo 2                 #
#  Luis Colorado 09-11086  #
#  Nicolas Manan 06-39883  #
############################



import ply.lex as lex

# Palabras reservadas del lenguaje
reserved = {
    
    # Del lenguaje
    'program' : 'TokenProgram',
    'using'   : 'TokenUsing',
    'scan'    : 'TokenScan',
    'print'   : 'TokenPrint',
    'println' : 'TokenPrintln',

    # Tipos de datos
    'int'   : 'TokenInt',
    'set'   : 'TokenSet',
    'bool'  : 'TokenBool',

    # Booleanos
    'true'  : 'TokenTrue',
    'false' : 'TokenFalse',

    # -------
    'in'      : 'TokenIn',

    # Condicionales
    'if'   : 'TokenIf',
    'then' : 'TokenThen',
    'else' : 'TokenElse',

    # Ciclos
    'do'    : 'TokenDo',
    'while' : 'TokenWhile',
    'repeat': 'TokenRepeat',
    'for'   : 'TokenFor',

    # Operadores
    'or'  : 'TokenOr',
    'and' : 'TokenAnd',
    'not' : 'TokenNot',
    'min' : 'TokenMin',
    'max' : 'TokenMax',

    # Funciones
    'def'   : 'TokenDef',
    'return': 'TokenReturn',
}

# Tokens a reconocer
tokens = [
    

    # Identificador
    'TokenID',

    # Operadores
    'TokenNumber',
    'TokenComma',
    'TokenAssing',
    'TokenSemicolon',
    'TokenOpenCurly',
    'TokenCloseCurly',
    'TokenArrow',
    'TokenString',
    'TokenPlus',
    'TokenMinus',
    'TokenTimes',
    'TokenDivide',
    'TokenModule',
    'TokenLParen',
    'TokenRParen',
    'TokenIntersection',
    'TokenLess',
    'TokenLessq',
    'TokenGreat',
    'TokenGreateq',
    'TokenEqual',
    'TokenUnequal',
    'TokenUnion',
    'TokenSubset',
    'TokenMinValue',
    'TokenMaxValue',
    'TokenNumberElements',
    'TokenMinusMap',
    'TokenPlusMap',
    'TokenDivideMap',
    'TokenTimesMap',
    'TokenModuleMap'
] + list(reserved.values())

# Devuelve el valor actual del tipo entero
def t_TokenNumber(t):
    r'\d+'
    t.value = int(t.value)
    return t


# Si no coinciden con las palabras reservadas,
# entonces es identificador
def t_TokenID(t):
    r'\w[\w\d]*'
    t.type = reserved.get(t.value, 'TokenID')
    return t

# Definiendo los simbolos
t_TokenComma = r','
t_TokenAssing = r'='
t_TokenSemicolon = r';'
t_TokenArrow = r'->'
t_TokenString = r'"[^"\\\r\n]*(?:\\.[^"\\\r\n]*)*"'
t_TokenOpenCurly = r'{'
t_TokenCloseCurly = r'}'
t_TokenPlus = r'\+'
t_TokenMinus = r'-'
t_TokenTimes = r'\*'
t_TokenDivide = r'/'
t_TokenModule = r'%'
t_TokenLParen = r'\('
t_TokenRParen = r'\)'
t_TokenIntersection = r'><'
t_TokenLess = r'<'
t_TokenLessq = r'<='
t_TokenGreat = r'>'
t_TokenGreateq = r'>='
t_TokenEqual = r'=='
t_TokenUnequal = r'/='
t_TokenUnion = r'\+\+'
t_TokenMinValue = r'<\?'
t_TokenMaxValue = r'>\?'
t_TokenNumberElements = r'\$\?'
t_TokenPlusMap = r'<\+>'
t_TokenMinusMap = r'<->'
t_TokenTimesMap = r'<\*>'
t_TokenDivideMap = r'</>'
t_TokenModuleMap = r'<%>'
t_TokenSubset = r'@'

# Comentarios, espacios y tabuladores son ignorados
t_ignore = " \t"
t_ignore_COMMENT = r'[#].*'

# El salto de linea se considera
def t_newline(t):
    r'\n+'
    t.lexer.lineno += t.value.count('\n')

# Funcion que busca el numero de la columna y linea
# actual
def find_column(text,token):
    last_cr = text.rfind('\n',0,token.lexpos)
    if last_cr < 0:
        last_cr = -1
    column = token.lexpos - last_cr
    return column

# Funcion que muestar el Error si se encuentra un caracter
# inesperado en el programa y su ubicacion en fila y columna
def t_error(t):
    errors_list.append("ERROR: Se encontro un caracter inesperado \"%s\" en la linea %d, columna %d"
                       % (t.value[0], t.lineno, find_column(lexer.lexdata, t)))
    t.lexer.skip(1)

# Funcion que a traves del lexer toma el archivo a ser leido 
# y devuelve la lista de tokens
def lexing(file):

    global errors_list, lexer

    lexer = lex.lex()
    tokens_list = []
    errors_list = []

    lexer.input(file)

    for tok in lexer:
        tokens_list.append(tok)

    if not errors_list:
        return tokens_list
    else:

        for error in errors_list:
            print error

        return []

# Modulo main
def main(argv = None):
    import sys    # argv, exit

    if argv is None:
        argv = sys.argv

    if len(argv) == 1:
        print "ERROR: No encuentra el archivo"
        sys.exit() #return
    elif len(argv) > 2:
        print "ERROR: Numero invalido de argumentos"
        sys.exit() #return

    # Abre el archivo a interpretar
    file = open(argv[1], 'r')

    # Lee el archivo que se le esta pasando a Lexer
    tokens_list = lexing(file.read())

    for tok in tokens_list:
        if(tok.type=='TokenID' or tok.type=='TokenString' or tok.type=='TokenNumber'):
            if(tok.type=='TokenString'):
                print "%s %s(Linea %s, Columna %s)" % (tok.type, tok.value, tok.lineno,str(find_column(lexer.lexdata,tok)))
            else:
                print "%s \"%s\": (Linea %s, Columna %s)" % (tok.type, tok.value, tok.lineno,str(find_column(lexer.lexdata,tok)))
        else:
            print str(tok.type) +'(Linea ' + str(tok.lineno) + ',',
            print 'Columna ' + str(find_column(lexer.lexdata, tok)) + ')'

# Modulo para correr el programa
if __name__ == "__main__":
    main()